{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "Starting from the xlsx files, let's convert them to `.csv`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 2009-A riformattato.xlsx to 2009-A riformattato.csv\n",
      "Converted 2010-A riformattato.xlsx to 2010-A riformattato.csv\n",
      "Converted 2011-A riformattato.xlsx to 2011-A riformattato.csv\n",
      "Converted 2012-A riformattato.xlsx to 2012-A riformattato.csv\n",
      "Converted 2013-A riformattato.xlsx to 2013-A riformattato.csv\n",
      "Converted 2014-A riformattato.xlsx to 2014-A riformattato.csv\n",
      "Converted 2015-A riformattato.xlsx to 2015-A riformattato.csv\n",
      "Converted 2016-A riformattato.xlsx to 2016-A riformattato.csv\n",
      "Converted 2017-A riformattato.xlsx to 2017-A riformattato.csv\n",
      "Converted 2018-A riformattato.xlsx to 2018-A riformattato.csv\n",
      "Converted 2019-A riformattato.xlsx to 2019-A riformattato.csv\n",
      "Converted 2020-A riformattato.xlsx to 2020-A riformattato.csv\n",
      "Converted 2021-A riformattato.xlsx to 2021-A riformattato.csv\n",
      "Converted 2022-A riformattato.xlsx to 2022-A riformattato.csv\n",
      "Converted 2023-A riformattato.xlsx to 2023-A riformattato.csv\n",
      "Conversion complete.\n"
     ]
    }
   ],
   "source": [
    "# Setting directories containing data:\n",
    "input_folder = \"../../DATA/XLSX\"\n",
    "output_folder = \"../../DATA/CSV\"\n",
    "\n",
    "# Creating output directory if it doesn't exist:\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Iterating over each file in the input directory:\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".xlsx\"):\n",
    "\n",
    "        # Creating full path to the xlsx file:\n",
    "        xlsx_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        # Reading the xlsx file:\n",
    "        try:\n",
    "            df = pd.read_excel(xlsx_path, engine=\"openpyxl\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Changing the filename extension to .csv:\n",
    "        csv_filename = filename.rsplit(\".\", 1)[0] + \".csv\"\n",
    "        csv_path = os.path.join(output_folder, csv_filename)\n",
    "\n",
    "        # Writing the dataframe to a csv file:\n",
    "        try:\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            print(f\"Converted {filename} to {csv_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not convert {filename}: {e}\")\n",
    "\n",
    "print(\"Conversion complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's possible to save the filenames in a global variable to use them when needed with the right extension; the directory containing the files will be saved too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    \"../../DATA/CSV/2009-A riformattato.csv\",\n",
    "    \"../../DATA/CSV/2010-A riformattato.csv\",\n",
    "    \"../../DATA/CSV/2011-A riformattato.csv\",\n",
    "    \"../../DATA/CSV/2012-A riformattato.csv\",\n",
    "    \"../../DATA/CSV/2013-A riformattato.csv\",\n",
    "    \"../../DATA/CSV/2014-A riformattato.csv\",\n",
    "    \"../../DATA/CSV/2015-A riformattato.csv\",\n",
    "    \"../../DATA/CSV/2016-A riformattato.csv\",\n",
    "    \"../../DATA/CSV/2017-A riformattato.csv\",\n",
    "    \"../../DATA/CSV/2018-A riformattato.csv\",\n",
    "    \"../../DATA/CSV/2019-A riformattato.csv\",\n",
    "    \"../../DATA/CSV/2020-A riformattato.csv\",\n",
    "    \"../../DATA/CSV/2021-A riformattato.csv\",\n",
    "    \"../../DATA/CSV/2022-A riformattato.csv\",\n",
    "    \"../../DATA/CSV/2023-A riformattato.csv\",\n",
    "]\n",
    "dir = \"../../DATA/CSV\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's important to uniform the names of the columns across files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and saved: ../../DATA/CSV/2009-A riformattato.csv\n",
      "Cleaned and saved: ../../DATA/CSV/2010-A riformattato.csv\n",
      "Cleaned and saved: ../../DATA/CSV/2011-A riformattato.csv\n",
      "Cleaned and saved: ../../DATA/CSV/2012-A riformattato.csv\n",
      "Cleaned and saved: ../../DATA/CSV/2013-A riformattato.csv\n",
      "Cleaned and saved: ../../DATA/CSV/2014-A riformattato.csv\n",
      "Cleaned and saved: ../../DATA/CSV/2015-A riformattato.csv\n",
      "Cleaned and saved: ../../DATA/CSV/2016-A riformattato.csv\n",
      "Cleaned and saved: ../../DATA/CSV/2017-A riformattato.csv\n",
      "Cleaned and saved: ../../DATA/CSV/2018-A riformattato.csv\n",
      "Cleaned and saved: ../../DATA/CSV/2019-A riformattato.csv\n",
      "Cleaned and saved: ../../DATA/CSV/2020-A riformattato.csv\n",
      "Cleaned and saved: ../../DATA/CSV/2021-A riformattato.csv\n",
      "Cleaned and saved: ../../DATA/CSV/2022-A riformattato.csv\n",
      "Cleaned and saved: ../../DATA/CSV/2023-A riformattato.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Defining uniform column names:\n",
    "uniform_column_mapping = {\n",
    "    \"classe_donatore\": \"donor_class\",\n",
    "    \"tipo\": \"donation_type\",\n",
    "    \"nascita\": \"birth_year\",\n",
    "    \"coorte_nascita\": \"birth_cohort\",\n",
    "    \"prima_donazione\": \"first_donation_year\",\n",
    "    \"coorte_prima_donazione\": \"first_donation_cohort\",\n",
    "    \"numero_donazioni\": \"number_of_donations\",\n",
    "    \"sesso\": \"gender\",\n",
    "    \"data\": \"year\",\n",
    "    \"ETÃ€\": \"age\",\n",
    "    \"ETA'\": \"age\",\n",
    "    \"UN\": \"unique_number\",\n",
    "}\n",
    "\n",
    "cleaned_files = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    # Loading the data:\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Dropping the first column regardless of its name:\n",
    "    data.drop(data.columns[0], axis=1, inplace=True)\n",
    "\n",
    "    # Renaming columns to uniform names:\n",
    "    data.rename(columns=uniform_column_mapping, inplace=True)\n",
    "\n",
    "    # Standardizing data types - ensuring numeric columns are in the right data format:\n",
    "    data[\"birth_year\"] = data[\"birth_year\"].astype(int, errors=\"ignore\")\n",
    "    data[\"birth_cohort\"] = data[\"birth_cohort\"].astype(int, errors=\"ignore\")\n",
    "    data[\"first_donation_year\"] = data[\"first_donation_year\"].astype(\n",
    "        int, errors=\"ignore\"\n",
    "    )\n",
    "    data[\"first_donation_cohort\"] = data[\"first_donation_cohort\"].astype(\n",
    "        int, errors=\"ignore\"\n",
    "    )\n",
    "    data[\"number_of_donations\"] = data[\"number_of_donations\"].astype(\n",
    "        int, errors=\"ignore\"\n",
    "    )\n",
    "\n",
    "    # Calculating missing 'age' data if possible:\n",
    "    data[\"age\"] = data.apply(\n",
    "        lambda row: (\n",
    "            row[\"year\"] - row[\"birth_year\"]\n",
    "            if pd.isna(row[\"age\"]) and row[\"birth_year\"] > 0\n",
    "            else row[\"age\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Saving the cleaned data:\n",
    "    data.to_csv(file_path, index=False)\n",
    "    cleaned_files.append(file_path)\n",
    "\n",
    "for file in cleaned_files:\n",
    "    print(f\"Cleaned and saved: {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe creation\n",
    "\n",
    "Now that the files are all cleaned and formatted, it's possible to create a dataframe with them using **pandas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the first few rows of the combined DataFrame:\n",
      "  donor_class donation_type  birth_year  birth_cohort  first_donation_year  \\\n",
      "0           P       PLASMAF         NaN           NaN               1998.0   \n",
      "1           O        SANGUE      1980.0        1980.0               2009.0   \n",
      "2           P       PLASMAF      1980.0        1980.0               2005.0   \n",
      "3           P       PLASMAF      1980.0        1980.0               2005.0   \n",
      "4           P       PLASMAF      1980.0        1980.0               2005.0   \n",
      "\n",
      "   first_donation_cohort  number_of_donations gender    year   age  \\\n",
      "0                 1995.0                  1.0      M  2009.0   NaN   \n",
      "1                 2005.0                  1.0      F  2009.0  29.0   \n",
      "2                 2005.0                  5.0      M  2009.0  29.0   \n",
      "3                 2005.0                  5.0      M  2009.0  29.0   \n",
      "4                 2005.0                  5.0      M  2009.0  29.0   \n",
      "\n",
      "   unique_number  \n",
      "0     27128310.0  \n",
      "1     26934057.0  \n",
      "2     26826075.0  \n",
      "3     26826075.0  \n",
      "4     26826075.0  \n",
      "\n",
      "Summary Information about the Combined DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 320734 entries, 0 to 320733\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   donor_class            318762 non-null  object \n",
      " 1   donation_type          318797 non-null  object \n",
      " 2   birth_year             318795 non-null  float64\n",
      " 3   birth_cohort           318795 non-null  float64\n",
      " 4   first_donation_year    268554 non-null  float64\n",
      " 5   first_donation_cohort  268554 non-null  float64\n",
      " 6   number_of_donations    318797 non-null  float64\n",
      " 7   gender                 318797 non-null  object \n",
      " 8   year                   318797 non-null  float64\n",
      " 9   age                    319616 non-null  float64\n",
      " 10  unique_number          319618 non-null  float64\n",
      "dtypes: float64(8), object(3)\n",
      "memory usage: 26.9+ MB\n",
      "None\n",
      "\n",
      "Displaying a random sample of 10 rows:\n",
      "       donor_class donation_type  birth_year  birth_cohort  \\\n",
      "270899           P       PLASMAF      1968.0        1965.0   \n",
      "287670           P       PLASMAF      1962.0        1960.0   \n",
      "178699           P        SANGUE      1972.0        1970.0   \n",
      "66666            O        SANGUE      1963.0        1960.0   \n",
      "110154           P        SANGUE      1984.0        1980.0   \n",
      "264094           P       PLASMAF      1975.0        1975.0   \n",
      "28006            P        SANGUE      1964.0        1960.0   \n",
      "157319           P        SANGUE      1968.0        1965.0   \n",
      "93977            P        SANGUE      1971.0        1970.0   \n",
      "165119           P       PLASMAF      1957.0        1955.0   \n",
      "\n",
      "        first_donation_year  first_donation_cohort  number_of_donations  \\\n",
      "270899               2015.0                 2015.0                  7.0   \n",
      "287670               1994.0                 1990.0                  3.0   \n",
      "178699               2008.0                 2005.0                  4.0   \n",
      "66666                2011.0                 2010.0                  1.0   \n",
      "110154               2004.0                 2000.0                  1.0   \n",
      "264094               2015.0                 2015.0                  3.0   \n",
      "28006                   NaN                    NaN                  2.0   \n",
      "157319               2001.0                 2000.0                  1.0   \n",
      "93977                2004.0                 2000.0                  3.0   \n",
      "165119               1984.0                 1980.0                  3.0   \n",
      "\n",
      "       gender    year   age  unique_number  \n",
      "270899      M  2021.0  53.0     27062223.0  \n",
      "287670      M  2022.0  60.0     26463408.0  \n",
      "178699      M  2016.0  44.0     26901579.0  \n",
      "66666       M  2011.0  48.0     26982792.0  \n",
      "110154      M  2013.0  29.0     26802666.0  \n",
      "264094      M  2020.0  45.0     26642463.0  \n",
      "28006       M  2010.0  46.0     26456958.0  \n",
      "157319      M  2015.0  47.0     26821704.0  \n",
      "93977       M  2012.0  41.0     26807010.0  \n",
      "165119      M  2016.0  59.0     26457501.0  \n"
     ]
    }
   ],
   "source": [
    "# Creating a dataframe for each individual file:\n",
    "dataframes = []\n",
    "\n",
    "# Iterating over each file in the directory:\n",
    "for file in file_paths:\n",
    "    if file.endswith(\".csv\"):\n",
    "\n",
    "        # Creating the dataframe for the current file:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        # Appending the dataframe to the list:\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Creating the final dataframe by concatenating all the individual dataframes:\n",
    "combined_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "print(\"Displaying the first few rows of the combined DataFrame:\")\n",
    "print(combined_dataframe.head())\n",
    "\n",
    "print(\"\\nSummary Information about the Combined DataFrame:\")\n",
    "print(combined_dataframe.info())\n",
    "\n",
    "print(\"\\nDisplaying a random sample of 10 rows:\")\n",
    "print(combined_dataframe.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping NaN values\n",
    "\n",
    "Lines with missing values are usually dropped from the dataset; some values, however, can be calculated indirectly using other variables (e.g. \"age\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 320734 entries, 0 to 320733\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   donor_class            318762 non-null  object \n",
      " 1   donation_type          318797 non-null  object \n",
      " 2   birth_year             318795 non-null  float64\n",
      " 3   birth_cohort           318795 non-null  float64\n",
      " 4   first_donation_year    268554 non-null  float64\n",
      " 5   first_donation_cohort  268554 non-null  float64\n",
      " 6   number_of_donations    318797 non-null  float64\n",
      " 7   gender                 318797 non-null  object \n",
      " 8   year                   318797 non-null  float64\n",
      " 9   age                    319616 non-null  float64\n",
      " 10  unique_number          319618 non-null  float64\n",
      "dtypes: float64(8), object(3)\n",
      "memory usage: 26.9+ MB\n",
      "None\n",
      "Summary after dropping rows with missing values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 268530 entries, 1 to 320733\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   donor_class            268530 non-null  object \n",
      " 1   donation_type          268530 non-null  object \n",
      " 2   birth_year             268530 non-null  float64\n",
      " 3   birth_cohort           268530 non-null  float64\n",
      " 4   first_donation_year    268530 non-null  float64\n",
      " 5   first_donation_cohort  268530 non-null  float64\n",
      " 6   number_of_donations    268530 non-null  float64\n",
      " 7   gender                 268530 non-null  object \n",
      " 8   year                   268530 non-null  float64\n",
      " 9   age                    268530 non-null  float64\n",
      " 10  unique_number          268530 non-null  float64\n",
      "dtypes: float64(8), object(3)\n",
      "memory usage: 24.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(combined_dataframe.info())\n",
    "# Drop rows where any column has NaN values\n",
    "combined_dataframe_cleaned = combined_dataframe.dropna()\n",
    "\n",
    "# Display a summary to verify\n",
    "print(\"Summary after dropping rows with missing values:\")\n",
    "print(combined_dataframe_cleaned.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Now that the dataframe is ready to be used, it's possible to save it to a single `.csv` file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataframe_cleaned.to_csv(\"../../DATA/FINAL/dataframe_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
